\contentsline {section}{\numberline {1}Neuronale Netze - kurzer \IeC {\"U}berblick}{5}{section.1}
\contentsline {section}{\numberline {2}Pattern Recognition}{8}{section.2}
\contentsline {subsection}{\numberline {2.1}Data Feature}{9}{subsection.2.1}
\contentsline {subsubsection}{\numberline {2.1.1}Preprocessing:}{9}{subsubsection.2.1.1}
\contentsline {subsubsection}{\numberline {2.1.2}Comparison}{9}{subsubsection.2.1.2}
\contentsline {subsection}{\numberline {2.2}Parametric Methods}{9}{subsection.2.2}
\contentsline {subsubsection}{\numberline {2.2.1}Bayes Decision Theory}{9}{subsubsection.2.2.1}
\contentsline {subsubsection}{\numberline {2.2.2}Mixture Densities}{10}{subsubsection.2.2.2}
\contentsline {subsection}{\numberline {2.3}Classifier Discrimination Function}{10}{subsection.2.3}
\contentsline {subsection}{\numberline {2.4}Curse of Dimensionality}{11}{subsection.2.4}
\contentsline {subsubsection}{\numberline {2.4.1}Principle Component Analysis (PCA)}{11}{subsubsection.2.4.1}
\contentsline {subsection}{\numberline {2.5}Non-Parametric Methods}{11}{subsection.2.5}
\contentsline {subsubsection}{\numberline {2.5.1}Parzen Window}{11}{subsubsection.2.5.1}
\contentsline {subsubsection}{\numberline {2.5.2}k-nearest Neighours}{11}{subsubsection.2.5.2}
\contentsline {subsubsection}{\numberline {2.5.3}Clustering}{12}{subsubsection.2.5.3}
\contentsline {subsection}{\numberline {2.6}Fisher-Linear Discriminant}{12}{subsection.2.6}
\contentsline {subsection}{\numberline {2.7}Perceptron}{12}{subsection.2.7}
\contentsline {section}{\numberline {3}Recurrent Neural Networks}{13}{section.3}
\contentsline {subsection}{\numberline {3.1}Sequence Learning}{13}{subsection.3.1}
\contentsline {subsection}{\numberline {3.2}Elman vs. Jordan Networks - Simple RNN}{13}{subsection.3.2}
\contentsline {subsection}{\numberline {3.3}Aufbau}{13}{subsection.3.3}
\contentsline {subsection}{\numberline {3.4}Training}{14}{subsection.3.4}
\contentsline {subsection}{\numberline {3.5}Vanishing / Exploding Gradient}{15}{subsection.3.5}
\contentsline {section}{\numberline {4}Backpropagation}{16}{section.4}
\contentsline {subsection}{\numberline {4.1}Regularization}{18}{subsection.4.1}
\contentsline {subsubsection}{\numberline {4.1.1}Weight Elimination}{18}{subsubsection.4.1.1}
\contentsline {subsubsection}{\numberline {4.1.2}Optimal Brain Damage}{18}{subsubsection.4.1.2}
\contentsline {subsubsection}{\numberline {4.1.3}Cascade Correlation}{19}{subsubsection.4.1.3}
\contentsline {subsubsection}{\numberline {4.1.4}Meiosis Network}{19}{subsubsection.4.1.4}
\contentsline {section}{\numberline {5}Speech}{20}{section.5}
\contentsline {subsection}{\numberline {5.1}Speech Recognition}{20}{subsection.5.1}
\contentsline {subsection}{\numberline {5.2}Acoustic Model}{21}{subsection.5.2}
\contentsline {subsubsection}{\numberline {5.2.1}Hidden Markov Model}{21}{subsubsection.5.2.1}
\contentsline {subsubsection}{\numberline {5.2.2}Time Delay Neural Network (TDNN)}{22}{subsubsection.5.2.2}
\contentsline {subsection}{\numberline {5.3}Word Model}{23}{subsection.5.3}
\contentsline {subsubsection}{\numberline {5.3.1}Time Alignment}{24}{subsubsection.5.3.1}
\contentsline {subsubsection}{\numberline {5.3.2}Multi-State-TDNN}{24}{subsubsection.5.3.2}
\contentsline {subsubsection}{\numberline {5.3.3}NN-HMM Hybride}{25}{subsubsection.5.3.3}
\contentsline {subsubsection}{\numberline {5.3.4}Viterbi-Algorithmus}{25}{subsubsection.5.3.4}
\contentsline {subsubsection}{\numberline {5.3.5}Forward-Algorithmus}{26}{subsubsection.5.3.5}
\contentsline {subsubsection}{\numberline {5.3.6}Backward-Algorithmus}{26}{subsubsection.5.3.6}
\contentsline {section}{\numberline {6}Learning Vector Quantization}{27}{section.6}
\contentsline {subsection}{\numberline {6.1}Vector Quantization}{27}{subsection.6.1}
\contentsline {subsubsection}{\numberline {6.1.1}Applications}{27}{subsubsection.6.1.1}
\contentsline {subsubsection}{\numberline {6.1.2}Training}{27}{subsubsection.6.1.2}
\contentsline {subsection}{\numberline {6.2}Learning Vector Quantization}{27}{subsection.6.2}
\contentsline {subsubsection}{\numberline {6.2.1}LVQ1}{28}{subsubsection.6.2.1}
\contentsline {subsubsection}{\numberline {6.2.2}LVQ2}{28}{subsubsection.6.2.2}
\contentsline {subsubsection}{\numberline {6.2.3}LVQ2.1}{29}{subsubsection.6.2.3}
\contentsline {subsubsection}{\numberline {6.2.4}LVQ3}{29}{subsubsection.6.2.4}
\contentsline {subsubsection}{\numberline {6.2.5}OLVQ}{29}{subsubsection.6.2.5}
\contentsline {section}{\numberline {7}Self-Organizing-Maps}{30}{section.7}
\contentsline {subsection}{\numberline {7.1}Principles Of Self-Oragnized-Learning}{30}{subsection.7.1}
\contentsline {subsubsection}{\numberline {7.1.1}Principle 1: Self-Amplification}{30}{subsubsection.7.1.1}
\contentsline {subsubsection}{\numberline {7.1.2}Principle 2: Competition}{30}{subsubsection.7.1.2}
\contentsline {subsubsection}{\numberline {7.1.3}Principle 3: Cooperation}{30}{subsubsection.7.1.3}
\contentsline {subsubsection}{\numberline {7.1.4}Principle 4: Structural Information}{30}{subsubsection.7.1.4}
\contentsline {subsubsection}{\numberline {7.1.5}Hebbian Learning}{30}{subsubsection.7.1.5}
\contentsline {subsection}{\numberline {7.2}Self-Organizing-Maps}{30}{subsection.7.2}
\contentsline {section}{\numberline {8}Reinfocement Learning}{31}{section.8}
\contentsline {subsection}{\numberline {8.1}Bellman Equation}{33}{subsection.8.1}
\contentsline {subsection}{\numberline {8.2}Q-Learning}{33}{subsection.8.2}
\contentsline {subsection}{\numberline {8.3}Temporal Difference Learning}{34}{subsection.8.3}
\contentsline {subsubsection}{\numberline {8.3.1}SARSA}{34}{subsubsection.8.3.1}
\contentsline {subsection}{\numberline {8.4}Challenges}{34}{subsection.8.4}
\contentsline {section}{\numberline {9}Deep Learning in Computer Vision}{35}{section.9}
\contentsline {section}{\numberline {10}Neural Network Applications in Machine Translation}{36}{section.10}
\contentsline {subsection}{\numberline {10.1}Conventional Statistical MT}{36}{subsection.10.1}
\contentsline {subsection}{\numberline {10.2}Neural MT}{37}{subsection.10.2}
\contentsline {section}{\numberline {11}Speaker Independence}{40}{section.11}
\contentsline {subsection}{\numberline {11.1}Frequency Invariance}{41}{subsection.11.1}
\contentsline {subsection}{\numberline {11.2}Multi-Speaker Reference Model}{41}{subsection.11.2}
\contentsline {subsection}{\numberline {11.3}Cross-Language DNNs}{42}{subsection.11.3}
\contentsline {section}{\numberline {12}Hand Writing}{44}{section.12}
\contentsline {section}{\numberline {13}Natural Language Processing}{45}{section.13}
\contentsline {subsection}{\numberline {13.1}Language Model}{45}{subsection.13.1}
\contentsline {subsubsection}{\numberline {13.1.1}Word Embeddings}{46}{subsubsection.13.1.1}
\contentsline {subsubsection}{\numberline {13.1.2}Word2Vec}{46}{subsubsection.13.1.2}
\contentsline {subsection}{\numberline {13.2}Sentence Modeling}{46}{subsection.13.2}
\contentsline {subsubsection}{\numberline {13.2.1}Dynamic k-max Convolutional NN}{47}{subsubsection.13.2.1}
\contentsline {section}{\numberline {14}Gradient Optimizations and 2nd order Methods}{49}{section.14}
\contentsline {subsection}{\numberline {14.1}Logistic Regression}{49}{subsection.14.1}
\contentsline {subsubsection}{\numberline {14.1.1}Gradient Descent - General Approach}{49}{subsubsection.14.1.1}
\contentsline {subsubsection}{\numberline {14.1.2}Batch Gradient Descent}{50}{subsubsection.14.1.2}
\contentsline {subsubsection}{\numberline {14.1.3}Stochastic Gradient Descent}{50}{subsubsection.14.1.3}
\contentsline {subsubsection}{\numberline {14.1.4}Mini-Batch Gradient Descent}{50}{subsubsection.14.1.4}
\contentsline {subsection}{\numberline {14.2}Learning Rate Scheduling}{50}{subsection.14.2}
\contentsline {subsubsection}{\numberline {14.2.1}Adagrad - ADAptive GRADient method}{51}{subsubsection.14.2.1}
\contentsline {subsubsection}{\numberline {14.2.2}Adadelta}{51}{subsubsection.14.2.2}
\contentsline {subsubsection}{\numberline {14.2.3}RMSprop}{51}{subsubsection.14.2.3}
\contentsline {subsubsection}{\numberline {14.2.4}Adam - ADAptive Moment estimation}{52}{subsubsection.14.2.4}
\contentsline {section}{\numberline {15}Error Functions}{53}{section.15}
\contentsline {subsection}{\numberline {15.1}Binary Cross Entropy or Negative Log Likelihood}{53}{subsection.15.1}
\contentsline {section}{\numberline {16}Activation Functions}{54}{section.16}
\contentsline {subsection}{\numberline {16.1}Step Function}{54}{subsection.16.1}
\contentsline {subsection}{\numberline {16.2}Linear Function}{54}{subsection.16.2}
\contentsline {subsection}{\numberline {16.3}Logistic / Sigmoid Function}{54}{subsection.16.3}
\contentsline {subsection}{\numberline {16.4}Hyperbolic Tangent function}{55}{subsection.16.4}
\contentsline {subsection}{\numberline {16.5}Softmax Function}{55}{subsection.16.5}
\contentsline {subsection}{\numberline {16.6}Rectified Linear Unit}{55}{subsection.16.6}
